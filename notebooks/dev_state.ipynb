{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73478b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "\n",
    "project_root = Path().resolve().parent  \n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from src.receipt_intelligence.config import settings\n",
    "\n",
    "\n",
    "class ConversationState(TypedDict):\n",
    "    \"\"\"\n",
    "    State class for the LangGraph workflow. \n",
    "    It keeps track of the information necessary to maintain a coherent conversation between the user and the bot.\n",
    "\n",
    "    Attributes:\n",
    "        messages: A list of messages between the user and the bot.\n",
    "        message_type (str): Current message type, used for routing the message to the correct node.\n",
    "        summary (str): A summary of the conversation. This is used to reduce the token usage of the model.\n",
    "    \"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "    message_type: str | None\n",
    "    summary: str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b4a45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "testState = ConversationState(messages=[], message_type=None, summary=\"\")\n",
    "\n",
    "test_message = {\"role\": \"human\", \"content\": \"Hello, bot!\"}\n",
    "\n",
    "\n",
    "testState[\"messages\"] = testState.get(\"messages\") + [test_message]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a6097d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, bot!\n"
     ]
    }
   ],
   "source": [
    "last_message = testState[\"messages\"][-1]\n",
    "print(last_message['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89aabe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_model(temperature: float = 0.7, model_name: str = settings.GROQ_LLM_MODEL) -> ChatGroq:\n",
    "    \"\"\"\n",
    "    Returns a ChatGroq model instance with the given temperature and model name.\n",
    "    Defaults to standard settings.\n",
    "    \"\"\"\n",
    "    return ChatGroq(\n",
    "        api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "        model_name=model_name,\n",
    "        temperature=temperature,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9999822d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_message(state: ConversationState):\n",
    "    \n",
    "    last_message = state[\"messages\"][-1]\n",
    "    model = get_chat_model()\n",
    "\n",
    "    prompt = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Classify the user message as either: \"\n",
    "                \"'generate_sqlquery_node': if the user asks a question directly related to receipt data\"\n",
    "                \"'introduction_node': if the user asks about anything unrelated to the receipt data\"\n",
    "                \"You can only output one of these: 'generate_sqlquery_node' or 'introduction_node'\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": last_message['content']\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    response = model.invoke(prompt)\n",
    "\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5715bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classify_message(testState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6e426be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "introduction_node\n"
     ]
    }
   ],
   "source": [
    "type(result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240a6f28",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'messages'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Initial state\u001b[39;00m\n\u001b[32m      8\u001b[39m state = ConversationState()\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.append(HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mHello there!\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     12\u001b[39m last_message = state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m]\n",
      "\u001b[31mKeyError\u001b[39m: 'messages'"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.receipt_intelligence.modules.conversation_service.state import ConversationState\n",
    "from src.receipt_intelligence.modules.conversation_service.graph import graph   \n",
    "\n",
    "\n",
    "user_input = input(\"Message: \")\n",
    "\n",
    "# Initial state\n",
    "\n",
    "state: ConversationState = {\n",
    "    \"messages\": [],\n",
    "    \"message_type\": None,\n",
    "    \"summary\": \"\"\n",
    "}\n",
    "\n",
    "state[\"messages\"].append(HumanMessage(content=\"Hello there!\"))\n",
    "\n",
    "last_message = state[\"messages\"][-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baf283cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mlast_message\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'dict' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "print(last_message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
